# MemA: Memory Augmented Transformers using Neural Nearest Neighbor

### Citations

```bibtex
@misc{vaswani2017attention,
      title={Attention Is All You Need},
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

```bibtex
@misc{zhong2022training,
      title={Training Language Models with Memory Augmentation},
      author={Zexuan Zhong and Tao Lei and Danqi Chen},
      year={2022},
      eprint={2205.12674},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

```bibtex
@misc{plötz2018neural,
      title={Neural Nearest Neighbors Networks},
      author={Tobias Plötz and Stefan Roth},
      year={2018},
      eprint={1810.12575},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
